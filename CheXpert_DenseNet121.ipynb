{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet121_on_CheXpert\n",
    "[05_Optimizing_AUROC_Loss_with_DenseNet121_on_CheXpert.ipynb](https://github.com/Optimization-AI/LibAUC/blob/main/examples/05_Optimizing_AUROC_Loss_with_DenseNet121_on_CheXpert.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing LibAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libauc.losses import AUCMLoss, CrossEntropyLoss\n",
    "from libauc.optimizers import PESG, Adam\n",
    "from libauc.models import DenseNet121, DenseNet169\n",
    "from libauc.datasets import CheXpert\n",
    "\n",
    "import torch \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(SEED):\n",
    "    # REPRODUCIBILITY\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining\n",
    "- Multi-label classification (5 tasks)\n",
    "- Adam + CrossEntropy Loss\n",
    "- This step is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 191027 images in total, 23385 positive images, 167642 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1224\n",
      "\n",
      "Found 191027 images in total, 61493 positive images, 129534 negative images\n",
      "Edema(C1): imbalance ratio is 0.3219\n",
      "\n",
      "Found 191027 images in total, 12983 positive images, 178044 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0680\n",
      "\n",
      "Found 191027 images in total, 59583 positive images, 131444 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3119\n",
      "\n",
      "Found 191027 images in total, 76899 positive images, 114128 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4026\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 202 images in total, 66 positive images, 136 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.3267\n",
      "\n",
      "Found 202 images in total, 42 positive images, 160 negative images\n",
      "Edema(C1): imbalance ratio is 0.2079\n",
      "\n",
      "Found 202 images in total, 32 positive images, 170 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.1584\n",
      "\n",
      "Found 202 images in total, 75 positive images, 127 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3713\n",
      "\n",
      "Found 202 images in total, 64 positive images, 138 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.3168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\Hyunmin/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 66.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, BatchID=0, Val_AUC=0.5088, Best_Val_AUC=0.5088\n",
      "Epoch=0, BatchID=400, Val_AUC=0.8421, Best_Val_AUC=0.8421\n",
      "Epoch=0, BatchID=800, Val_AUC=0.8619, Best_Val_AUC=0.8619\n",
      "Epoch=0, BatchID=1200, Val_AUC=0.8580, Best_Val_AUC=0.8619\n",
      "Epoch=0, BatchID=1600, Val_AUC=0.8604, Best_Val_AUC=0.8619\n",
      "Epoch=0, BatchID=2000, Val_AUC=0.8766, Best_Val_AUC=0.8766\n",
      "Epoch=0, BatchID=2400, Val_AUC=0.8827, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=2800, Val_AUC=0.8726, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=3200, Val_AUC=0.8737, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=3600, Val_AUC=0.8660, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=4000, Val_AUC=0.8808, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=4400, Val_AUC=0.8759, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=4800, Val_AUC=0.8734, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=5200, Val_AUC=0.8698, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=5600, Val_AUC=0.8809, Best_Val_AUC=0.8827\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "root = 'D:/Data/AI604_project/CheXpert-v1.0-small/CheXpert-v1.0-small/'\n",
    "# Index: -1 denotes multi-label mode including 5 diseases\n",
    "traindSet = CheXpert(csv_path=root+'train.csv', image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='train', class_index=-1)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=-1)\n",
    "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, shuffle=False)\n",
    "\n",
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = DenseNet121(pretrained=True, last_activation=None, activations='relu', num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "CELoss = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# training\n",
    "best_val_auc = 0 \n",
    "for epoch in range(1):\n",
    "    for idx, data in enumerate(trainloader):\n",
    "      train_data, train_labels = data\n",
    "      train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n",
    "      y_pred = model(train_data)\n",
    "      loss = CELoss(y_pred, train_labels)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "        \n",
    "      # validation  \n",
    "      if idx % 400 == 0:\n",
    "         model.eval()\n",
    "         with torch.no_grad():    \n",
    "              test_pred = []\n",
    "              test_true = [] \n",
    "              for jdx, data in enumerate(testloader):\n",
    "                  test_data, test_labels = data\n",
    "                  test_data = test_data.cuda()\n",
    "                  y_pred = model(test_data)\n",
    "                  test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                  test_true.append(test_labels.numpy())\n",
    "            \n",
    "              test_true = np.concatenate(test_true)\n",
    "              test_pred = np.concatenate(test_pred)\n",
    "              val_auc_mean =  roc_auc_score(test_true, test_pred) \n",
    "              model.train()\n",
    "\n",
    "              if best_val_auc < val_auc_mean:\n",
    "                 best_val_auc = val_auc_mean\n",
    "                 torch.save(model.state_dict(), 'ce_pretrained_model.pth')\n",
    "\n",
    "              print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, val_auc_mean, best_val_auc ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing AUCM Loss\n",
    "- Binary Classification\n",
    "- PESG + AUCM Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyunmin\\Anaconda3\\envs\\pytorch10\\lib\\site-packages\\libauc\\datasets\\chexpert.py:35: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
      "C:\\Users\\Hyunmin\\Anaconda3\\envs\\pytorch10\\lib\\site-packages\\libauc\\datasets\\chexpert.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampling Cardiomegaly...\n",
      "Upsampling Consolidation...\n",
      "------------------------------\n",
      "Found 227395 images in total, 77866 positive images, 149529 negative images\n",
      "Edema(C1): imbalance ratio is 0.3424\n",
      "------------------------------\n",
      "------------------------------\n",
      "Found 202 images in total, 42 positive images, 160 negative images\n",
      "Edema(C1): imbalance ratio is 0.2079\n",
      "------------------------------\n",
      "Epoch=0, BatchID=0, Val_AUC=0.6091, lr=0.0500\n",
      "Epoch=0, BatchID=400, Val_AUC=0.9010, lr=0.0500\n",
      "Epoch=0, BatchID=800, Val_AUC=0.9287, lr=0.0500\n",
      "Epoch=0, BatchID=1200, Val_AUC=0.9088, lr=0.0500\n",
      "Epoch=0, BatchID=1600, Val_AUC=0.8658, lr=0.0500\n",
      "Epoch=0, BatchID=2000, Val_AUC=0.9210, lr=0.0500\n",
      "Epoch=0, BatchID=2400, Val_AUC=0.9225, lr=0.0500\n",
      "Epoch=0, BatchID=2800, Val_AUC=0.9235, lr=0.0500\n",
      "Epoch=0, BatchID=3200, Val_AUC=0.9299, lr=0.0500\n",
      "Epoch=0, BatchID=3600, Val_AUC=0.9015, lr=0.0500\n",
      "Epoch=0, BatchID=4000, Val_AUC=0.9138, lr=0.0500\n",
      "Epoch=0, BatchID=4400, Val_AUC=0.9229, lr=0.0500\n",
      "Epoch=0, BatchID=4800, Val_AUC=0.9033, lr=0.0500\n",
      "Epoch=0, BatchID=5200, Val_AUC=0.9290, lr=0.0500\n",
      "Epoch=0, BatchID=5600, Val_AUC=0.9318, lr=0.0500\n",
      "Epoch=0, BatchID=6000, Val_AUC=0.9183, lr=0.0500\n",
      "Epoch=0, BatchID=6400, Val_AUC=0.9138, lr=0.0500\n",
      "Epoch=0, BatchID=6800, Val_AUC=0.8958, lr=0.0500\n",
      "Reducing learning rate to 0.00500 @ T=7107!\n",
      "Updating regularizer @ T=7107!\n",
      "Epoch=1, BatchID=0, Val_AUC=0.9182, lr=0.0050\n",
      "Epoch=1, BatchID=400, Val_AUC=0.9278, lr=0.0050\n",
      "Epoch=1, BatchID=800, Val_AUC=0.9336, lr=0.0050\n",
      "Epoch=1, BatchID=1200, Val_AUC=0.9313, lr=0.0050\n",
      "Epoch=1, BatchID=1600, Val_AUC=0.9274, lr=0.0050\n",
      "Epoch=1, BatchID=2000, Val_AUC=0.9299, lr=0.0050\n",
      "Epoch=1, BatchID=2400, Val_AUC=0.9259, lr=0.0050\n",
      "Epoch=1, BatchID=2800, Val_AUC=0.9318, lr=0.0050\n",
      "Epoch=1, BatchID=3200, Val_AUC=0.9280, lr=0.0050\n",
      "Epoch=1, BatchID=3600, Val_AUC=0.9362, lr=0.0050\n",
      "Epoch=1, BatchID=4000, Val_AUC=0.9390, lr=0.0050\n",
      "Epoch=1, BatchID=4400, Val_AUC=0.9382, lr=0.0050\n",
      "Epoch=1, BatchID=4800, Val_AUC=0.9287, lr=0.0050\n",
      "Epoch=1, BatchID=5200, Val_AUC=0.9321, lr=0.0050\n",
      "Epoch=1, BatchID=5600, Val_AUC=0.9385, lr=0.0050\n",
      "Epoch=1, BatchID=6000, Val_AUC=0.9396, lr=0.0050\n",
      "Epoch=1, BatchID=6400, Val_AUC=0.9460, lr=0.0050\n",
      "Epoch=1, BatchID=6800, Val_AUC=0.9375, lr=0.0050\n",
      "Best Val_AUC is 0.9460\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "class_id = 1 # 0:Cardiomegaly, 1:Edema, 2:Consolidation, 3:Atelectasis, 4:Pleural Effusion \n",
    "root = 'D:/Data/AI604_project/CheXpert-v1.0-small/CheXpert-v1.0-small/'\n",
    "\n",
    "# You can set use_upsampling=True and pass the class name by upsampling_cols=['Cardiomegaly'] to do upsampling. This may improve the performance\n",
    "traindSet = CheXpert(csv_path=root+'train.csv', image_root_path=root, use_upsampling=True, use_frontal=True, image_size=224, mode='train', class_index=class_id)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=class_id)\n",
    "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, shuffle=False)\n",
    "\n",
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "imratio = traindSet.imratio\n",
    "lr = 0.05 # using smaller learning rate is better\n",
    "gamma = 500\n",
    "weight_decay = 1e-5\n",
    "margin = 1.0\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = DenseNet121(pretrained=False, last_activation='sigmoid', activations='relu', num_classes=1)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "# load pretrained model\n",
    "if True:\n",
    "  PATH = 'ce_pretrained_model.pth' \n",
    "  state_dict = torch.load(PATH)\n",
    "  state_dict.pop('classifier.weight', None)\n",
    "  state_dict.pop('classifier.bias', None) \n",
    "  model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "\n",
    "# define loss & optimizer\n",
    "Loss = AUCMLoss(imratio=imratio)\n",
    "optimizer = PESG(model, \n",
    "                 a=Loss.a, \n",
    "                 b=Loss.b, \n",
    "                 alpha=Loss.alpha, \n",
    "                 imratio=imratio, \n",
    "                 lr=lr, \n",
    "                 gamma=gamma, \n",
    "                 margin=margin, \n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "best_val_auc = 0\n",
    "for epoch in range(2):\n",
    "  if epoch > 0:\n",
    "     optimizer.update_regularizer(decay_factor=10)\n",
    "  for idx, data in enumerate(trainloader):\n",
    "      train_data, train_labels = data\n",
    "      train_data, train_labels = train_data.cuda(), train_labels.cuda()\n",
    "      y_pred = model(train_data)\n",
    "      loss = Loss(y_pred, train_labels)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # validation\n",
    "      if idx % 400 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():    \n",
    "              test_pred = []\n",
    "              test_true = [] \n",
    "              for jdx, data in enumerate(testloader):\n",
    "                  test_data, test_label = data\n",
    "                  test_data = test_data.cuda()\n",
    "                  y_pred = model(test_data)\n",
    "                  test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                  test_true.append(test_label.numpy())\n",
    "              \n",
    "              test_true = np.concatenate(test_true)\n",
    "              test_pred = np.concatenate(test_pred)\n",
    "              val_auc =  roc_auc_score(test_true, test_pred) \n",
    "              model.train()\n",
    "\n",
    "              if best_val_auc < val_auc:\n",
    "                 best_val_auc = val_auc\n",
    "              \n",
    "        print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, lr=%.4f'%(epoch, idx, val_auc,  optimizer.lr))\n",
    "\n",
    "print ('Best Val_AUC is %.4f'%best_val_auc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1967738436216bbc6e595949f2989133cdf8326bfdf11bc95d02693bb68887ad"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('pytorch10': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
