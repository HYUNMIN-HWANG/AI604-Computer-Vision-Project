{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet121_on_CheXpert\n",
    "[05_Optimizing_AUROC_Loss_with_DenseNet121_on_CheXpert.ipynb](https://github.com/Optimization-AI/LibAUC/blob/main/examples/05_Optimizing_AUROC_Loss_with_DenseNet121_on_CheXpert.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Summary >\n",
    "### 1. Pre-training\n",
    "- train dataset : 191,027 images\n",
    "- test dataset : 202 images\n",
    "- 5 categories : Cardiomegaly, Edema, Consolidation, Atelectasis, Pleural Effusion\n",
    "- pre-trained model : DenseNet121\n",
    "- epoch 2\n",
    "- Loss : CrossEntropyLoss\n",
    "- Optimizer : Adam(lr=1e-4)\n",
    "- BATCH_SIZE : 32\n",
    "- Best Val_AUC : 0.9026\n",
    "\n",
    "### 2. Optimizing AUCM Loss\n",
    "- train dataset : 227,395 images\n",
    "- test dataset : 202 images\n",
    "- choose one categories\n",
    "- pre-trained model : DenseNet121 or saved model at first step\n",
    "- epoch 2\n",
    "- Loss : AUCMLoss\n",
    "- optimizer : PESG(lr=0.05)\n",
    "- BATCH_SIZE : 32\n",
    "- Best Val_AUC : 0.9467\n",
    "\n",
    "### 3. Multi-Label Training\n",
    "- train dataset : 191,027 images\n",
    "- test dataset : 202 images\n",
    "- 5 categories : Cardiomegaly, Edema, Consolidation, Atelectasis, Pleural Effusion\n",
    "- pre-trained model : DenseNet121\n",
    "- epoch 2\n",
    "- Loss : AUCM_MultiLabel\n",
    "- optimizer : PESG(lr=0.1)\n",
    "- BATCH_SIZE : 32\n",
    "- Best Val_AUC : 0.8939\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing LibAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libauc.losses import AUCMLoss, CrossEntropyLoss, AUCM_MultiLabel\n",
    "from libauc.optimizers import PESG, Adam\n",
    "from libauc.models import DenseNet121, DenseNet169, DenseNet201, DenseNet161\n",
    "from libauc.datasets import CheXpert\n",
    "\n",
    "import torch \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(SEED):\n",
    "    # REPRODUCIBILITY\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Pretraining\n",
    "- Multi-label classification (5 tasks)\n",
    "- Adam + CrossEntropy Loss\n",
    "- This step is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyunmin\\Anaconda3\\envs\\pytorch10\\lib\\site-packages\\libauc\\datasets\\chexpert.py:35: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
      "C:\\Users\\Hyunmin\\Anaconda3\\envs\\pytorch10\\lib\\site-packages\\libauc\\datasets\\chexpert.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 191027 images in total, 23385 positive images, 167642 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1224\n",
      "\n",
      "Found 191027 images in total, 61493 positive images, 129534 negative images\n",
      "Edema(C1): imbalance ratio is 0.3219\n",
      "\n",
      "Found 191027 images in total, 12983 positive images, 178044 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0680\n",
      "\n",
      "Found 191027 images in total, 59583 positive images, 131444 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3119\n",
      "\n",
      "Found 191027 images in total, 76899 positive images, 114128 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4026\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 202 images in total, 66 positive images, 136 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.3267\n",
      "\n",
      "Found 202 images in total, 42 positive images, 160 negative images\n",
      "Edema(C1): imbalance ratio is 0.2079\n",
      "\n",
      "Found 202 images in total, 32 positive images, 170 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.1584\n",
      "\n",
      "Found 202 images in total, 75 positive images, 127 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3713\n",
      "\n",
      "Found 202 images in total, 64 positive images, 138 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.3168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "root = 'D:/Data/AI604_project/CheXpert-v1.0-small/CheXpert-v1.0-small/'\n",
    "# Index: -1 denotes multi-label mode including 5 diseases\n",
    "traindSet = CheXpert(csv_path=root+'train.csv', image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='train', class_index=-1)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=-1)\n",
    "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5970\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader))\n",
    "print(len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (elu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (ELU): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (ELU): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (ELU): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=5, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-5\n",
    "\n",
    "name = 'DenseNet121' # ['DenseNet121', 'DenseNet169', 'DenseNet201', 'DenseNet161']\n",
    "\n",
    "if name == 'DenseNet121' :\n",
    "    model_name = DenseNet121\n",
    "elif name == 'DenseNet169' :\n",
    "    model_name = DenseNet169\n",
    "elif name == 'DenseNet201' :\n",
    "    model_name = DenseNet201\n",
    "else :\n",
    "    model_name = DenseNet161\n",
    "\n",
    "writer = SummaryWriter('CheXpert_tensorboard')\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = model_name(pretrained=True, last_activation=None, activations='relu', num_classes=5)   \n",
    "model = model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss & optimizer\n",
    "CELoss = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, BatchID=[0/5970] | Loss=0.717473, Val_AUC=0.5088, Best_Val_AUC=0.5088\n",
      "Epoch=0, BatchID=[400/5970] | Loss=0.405873, Val_AUC=0.8421, Best_Val_AUC=0.8421\n",
      "Epoch=0, BatchID=[800/5970] | Loss=0.349457, Val_AUC=0.8619, Best_Val_AUC=0.8619\n",
      "Epoch=0, BatchID=[1200/5970] | Loss=0.370392, Val_AUC=0.8580, Best_Val_AUC=0.8619\n",
      "Epoch=0, BatchID=[1600/5970] | Loss=0.435774, Val_AUC=0.8604, Best_Val_AUC=0.8619\n",
      "Epoch=0, BatchID=[2000/5970] | Loss=0.519603, Val_AUC=0.8766, Best_Val_AUC=0.8766\n",
      "Epoch=0, BatchID=[2400/5970] | Loss=0.388614, Val_AUC=0.8827, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=[2800/5970] | Loss=0.455310, Val_AUC=0.8726, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=[3200/5970] | Loss=0.446751, Val_AUC=0.8737, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=[3600/5970] | Loss=0.343250, Val_AUC=0.8660, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=[4000/5970] | Loss=0.491728, Val_AUC=0.8808, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=[4400/5970] | Loss=0.364772, Val_AUC=0.8759, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=[4800/5970] | Loss=0.316663, Val_AUC=0.8734, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=[5200/5970] | Loss=0.436863, Val_AUC=0.8698, Best_Val_AUC=0.8827\n",
      "Epoch=0, BatchID=[5600/5970] | Loss=0.404962, Val_AUC=0.8809, Best_Val_AUC=0.8827\n",
      "Epoch=1, BatchID=[0/5970] | Loss=0.390672, Val_AUC=0.8786, Best_Val_AUC=0.8827\n",
      "Epoch=1, BatchID=[400/5970] | Loss=0.465292, Val_AUC=0.8678, Best_Val_AUC=0.8827\n",
      "Epoch=1, BatchID=[800/5970] | Loss=0.374837, Val_AUC=0.8797, Best_Val_AUC=0.8827\n",
      "Epoch=1, BatchID=[1200/5970] | Loss=0.417488, Val_AUC=0.8795, Best_Val_AUC=0.8827\n",
      "Epoch=1, BatchID=[1600/5970] | Loss=0.351085, Val_AUC=0.8876, Best_Val_AUC=0.8876\n",
      "Epoch=1, BatchID=[2000/5970] | Loss=0.320930, Val_AUC=0.8816, Best_Val_AUC=0.8876\n",
      "Epoch=1, BatchID=[2400/5970] | Loss=0.379589, Val_AUC=0.8742, Best_Val_AUC=0.8876\n",
      "Epoch=1, BatchID=[2800/5970] | Loss=0.376221, Val_AUC=0.8941, Best_Val_AUC=0.8941\n",
      "Epoch=1, BatchID=[3200/5970] | Loss=0.350662, Val_AUC=0.8806, Best_Val_AUC=0.8941\n",
      "Epoch=1, BatchID=[3600/5970] | Loss=0.422535, Val_AUC=0.8921, Best_Val_AUC=0.8941\n",
      "Epoch=1, BatchID=[4000/5970] | Loss=0.440567, Val_AUC=0.8782, Best_Val_AUC=0.8941\n",
      "Epoch=1, BatchID=[4400/5970] | Loss=0.445330, Val_AUC=0.8780, Best_Val_AUC=0.8941\n",
      "Epoch=1, BatchID=[4800/5970] | Loss=0.344053, Val_AUC=0.9026, Best_Val_AUC=0.9026\n",
      "Epoch=1, BatchID=[5200/5970] | Loss=0.393497, Val_AUC=0.8797, Best_Val_AUC=0.9026\n",
      "Epoch=1, BatchID=[5600/5970] | Loss=0.304345, Val_AUC=0.8878, Best_Val_AUC=0.9026\n",
      "Best Val_AUC is 0.9026\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = 0 \n",
    "loss_total = []\n",
    "\n",
    "for epoch in range(2):\n",
    "    for idx, data in enumerate(trainloader):\n",
    "      train_data, train_labels = data\n",
    "      # print(train_data.shape)    # torch.Size([32,3,224,224])\n",
    "      # print(train_labels)        # torch.Size([32, 5]) â†’ exapmle :: [[0., 1., 0., 0., 0.], [0., 0., 0., 1., 1.], [0., 1., 0., 0., 1.], \n",
    "      # print(train_labels.shape)\n",
    "      train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n",
    "      y_pred = model(train_data)\n",
    "      # print(\"y_pred shape\", y_pred.shape) # torch.Size([32, 5])\n",
    "      # print(y_pred) # [ 1.9280e-01,  1.2542e-04, -1.2416e+00,  4.4322e-01,  6.8606e-01], [-2.8613e-03, -5.7308e-01, -8.1134e-01,  6.5988e-01,  5.8159e-01], [ 5.5615e-01, -2.8245e-01, -8.8850e-01,  1.6961e-01,  4.4384e-01],\n",
    "      loss = CELoss(y_pred, train_labels)\n",
    "\n",
    "      loss_total += [loss.item()]\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # validation  \n",
    "      if idx % 400 == 0:\n",
    "         model.eval()\n",
    "         with torch.no_grad():    \n",
    "              test_pred = []\n",
    "              test_true = [] \n",
    "              for jdx, data in enumerate(testloader):\n",
    "                  test_data, test_labels = data\n",
    "                  test_data = test_data.cuda()\n",
    "                  y_pred = model(test_data)\n",
    "                  test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                  test_true.append(test_labels.numpy())\n",
    "            \n",
    "              test_true = np.concatenate(test_true)\n",
    "              test_pred = np.concatenate(test_pred)\n",
    "              val_auc_mean =  roc_auc_score(test_true, test_pred) \n",
    "\n",
    "              writer.add_scalar('Pretraining/CELoss', np.mean(loss_total), epoch*len(trainloader) + idx)\n",
    "              writer.add_scalar('Pretraining/VAL AUC', np.mean(val_auc_mean), epoch*len(trainloader) + idx)\n",
    "              model.train()\n",
    "              \n",
    "              if best_val_auc < val_auc_mean:\n",
    "                 best_val_auc = val_auc_mean\n",
    "                 torch.save(model.state_dict(), 'checkpoints/DenseNet121_pretrained_model.pth')\n",
    "\n",
    "              print ('Epoch=%s, BatchID=[%s/%s] | Loss=%f, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, len(trainloader), loss.item(), val_auc_mean, best_val_auc ))\n",
    "\n",
    "print ('Best Val_AUC is %.4f' % best_val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Optimizing AUCM Loss\n",
    "- Binary Classification\n",
    "- PESG + AUCM Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyunmin\\Anaconda3\\envs\\pytorch10\\lib\\site-packages\\libauc\\datasets\\chexpert.py:35: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
      "C:\\Users\\Hyunmin\\Anaconda3\\envs\\pytorch10\\lib\\site-packages\\libauc\\datasets\\chexpert.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampling Cardiomegaly...\n",
      "Upsampling Consolidation...\n",
      "------------------------------\n",
      "Found 227395 images in total, 77866 positive images, 149529 negative images\n",
      "Edema(C1): imbalance ratio is 0.3424\n",
      "------------------------------\n",
      "------------------------------\n",
      "Found 202 images in total, 42 positive images, 160 negative images\n",
      "Edema(C1): imbalance ratio is 0.2079\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "class_id = 1 # 0:Cardiomegaly, 1:Edema, 2:Consolidation, 3:Atelectasis, 4:Pleural Effusion \n",
    "\n",
    "# You can set use_upsampling=True and pass the class name by upsampling_cols=['Cardiomegaly'] to do upsampling. This may improve the performance\n",
    "traindSet = CheXpert(csv_path=root+'train.csv', image_root_path=root, use_upsampling=True, use_frontal=True, image_size=224, mode='train', class_index=class_id)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=class_id)\n",
    "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7107\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader))\n",
    "print(len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "imratio = traindSet.imratio\n",
    "lr = 0.05 # using smaller learning rate is better\n",
    "gamma = 500\n",
    "weight_decay = 1e-5\n",
    "margin = 1.0\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = DenseNet121(pretrained=False, last_activation='sigmoid', activations='relu', num_classes=1)\n",
    "model = model.cuda()\n",
    "\n",
    "# load pretrained model\n",
    "if True:\n",
    "  PATH = 'checkpoints/DenseNet121_pretrained_model.pth' \n",
    "  state_dict = torch.load(PATH)\n",
    "  state_dict.pop('classifier.weight', None)\n",
    "  state_dict.pop('classifier.bias', None) \n",
    "  model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "\n",
    "# define loss & optimizer\n",
    "Loss = AUCMLoss(imratio=imratio)\n",
    "optimizer = PESG(model, \n",
    "                 a=Loss.a, \n",
    "                 b=Loss.b, \n",
    "                 alpha=Loss.alpha, \n",
    "                 imratio=imratio, \n",
    "                 lr=lr, \n",
    "                 gamma=gamma, \n",
    "                 margin=margin, \n",
    "                 weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, BatchID=[0/7107] | AUCM_Loss=0.147105, Val_AUC=0.6545, lr=0.0500\n",
      "Epoch=0, BatchID=[400/7107] | AUCM_Loss=0.097433, Val_AUC=0.9381, lr=0.0500\n",
      "Epoch=0, BatchID=[800/7107] | AUCM_Loss=0.135774, Val_AUC=0.9179, lr=0.0500\n",
      "Epoch=0, BatchID=[1200/7107] | AUCM_Loss=0.207467, Val_AUC=0.9314, lr=0.0500\n",
      "Epoch=0, BatchID=[1600/7107] | AUCM_Loss=0.215868, Val_AUC=0.8958, lr=0.0500\n",
      "Epoch=0, BatchID=[2000/7107] | AUCM_Loss=0.143644, Val_AUC=0.9418, lr=0.0500\n",
      "Epoch=0, BatchID=[2400/7107] | AUCM_Loss=0.125100, Val_AUC=0.9323, lr=0.0500\n",
      "Epoch=0, BatchID=[2800/7107] | AUCM_Loss=0.171456, Val_AUC=0.9192, lr=0.0500\n",
      "Epoch=0, BatchID=[3200/7107] | AUCM_Loss=0.100807, Val_AUC=0.9302, lr=0.0500\n",
      "Epoch=0, BatchID=[3600/7107] | AUCM_Loss=0.163123, Val_AUC=0.8972, lr=0.0500\n",
      "Epoch=0, BatchID=[4000/7107] | AUCM_Loss=0.188278, Val_AUC=0.9074, lr=0.0500\n",
      "Epoch=0, BatchID=[4400/7107] | AUCM_Loss=0.175530, Val_AUC=0.9217, lr=0.0500\n",
      "Epoch=0, BatchID=[4800/7107] | AUCM_Loss=0.034938, Val_AUC=0.8576, lr=0.0500\n",
      "Epoch=0, BatchID=[5200/7107] | AUCM_Loss=0.023560, Val_AUC=0.9173, lr=0.0500\n",
      "Epoch=0, BatchID=[5600/7107] | AUCM_Loss=0.201725, Val_AUC=0.9292, lr=0.0500\n",
      "Epoch=0, BatchID=[6000/7107] | AUCM_Loss=0.102910, Val_AUC=0.9254, lr=0.0500\n",
      "Epoch=0, BatchID=[6400/7107] | AUCM_Loss=0.003656, Val_AUC=0.9138, lr=0.0500\n",
      "Epoch=0, BatchID=[6800/7107] | AUCM_Loss=0.166667, Val_AUC=0.8930, lr=0.0500\n",
      "Reducing learning rate to 0.00500 @ T=7107!\n",
      "Updating regularizer @ T=7107!\n",
      "Epoch=1, BatchID=[0/7107] | AUCM_Loss=0.236706, Val_AUC=0.9077, lr=0.0050\n",
      "Epoch=1, BatchID=[400/7107] | AUCM_Loss=0.080058, Val_AUC=0.9272, lr=0.0050\n",
      "Epoch=1, BatchID=[800/7107] | AUCM_Loss=0.210242, Val_AUC=0.9330, lr=0.0050\n",
      "Epoch=1, BatchID=[1200/7107] | AUCM_Loss=0.134009, Val_AUC=0.9339, lr=0.0050\n",
      "Epoch=1, BatchID=[1600/7107] | AUCM_Loss=0.037713, Val_AUC=0.9283, lr=0.0050\n",
      "Epoch=1, BatchID=[2000/7107] | AUCM_Loss=0.172801, Val_AUC=0.9259, lr=0.0050\n",
      "Epoch=1, BatchID=[2400/7107] | AUCM_Loss=0.069121, Val_AUC=0.9250, lr=0.0050\n",
      "Epoch=1, BatchID=[2800/7107] | AUCM_Loss=0.084215, Val_AUC=0.9323, lr=0.0050\n",
      "Epoch=1, BatchID=[3200/7107] | AUCM_Loss=0.132743, Val_AUC=0.9272, lr=0.0050\n",
      "Epoch=1, BatchID=[3600/7107] | AUCM_Loss=0.102714, Val_AUC=0.9406, lr=0.0050\n",
      "Epoch=1, BatchID=[4000/7107] | AUCM_Loss=0.106863, Val_AUC=0.9400, lr=0.0050\n",
      "Epoch=1, BatchID=[4400/7107] | AUCM_Loss=0.015231, Val_AUC=0.9405, lr=0.0050\n",
      "Epoch=1, BatchID=[4800/7107] | AUCM_Loss=0.210562, Val_AUC=0.9228, lr=0.0050\n",
      "Epoch=1, BatchID=[5200/7107] | AUCM_Loss=0.114873, Val_AUC=0.9335, lr=0.0050\n",
      "Epoch=1, BatchID=[5600/7107] | AUCM_Loss=0.125933, Val_AUC=0.9329, lr=0.0050\n",
      "Epoch=1, BatchID=[6000/7107] | AUCM_Loss=0.234043, Val_AUC=0.9357, lr=0.0050\n",
      "Epoch=1, BatchID=[6400/7107] | AUCM_Loss=0.121470, Val_AUC=0.9467, lr=0.0050\n",
      "Epoch=1, BatchID=[6800/7107] | AUCM_Loss=0.085583, Val_AUC=0.9385, lr=0.0050\n",
      "Best Val_AUC is 0.9467\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = 0\n",
    "loss_total = []\n",
    "\n",
    "for epoch in range(2):\n",
    "  if epoch > 0:\n",
    "     optimizer.update_regularizer(decay_factor=10)\n",
    "  for idx, data in enumerate(trainloader):\n",
    "      train_data, train_labels = data     # train_labels shape : torch.Size([32, 1])\n",
    "      train_data, train_labels = train_data.cuda(), train_labels.cuda()\n",
    "      y_pred = model(train_data)\n",
    "      loss = Loss(y_pred, train_labels)\n",
    "      loss_total += [loss.item()]\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # validation\n",
    "      if idx % 400 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():    \n",
    "              test_pred = []\n",
    "              test_true = [] \n",
    "              for jdx, data in enumerate(testloader):\n",
    "                  test_data, test_label = data\n",
    "                  test_data = test_data.cuda()\n",
    "                  y_pred = model(test_data)\n",
    "                  test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                  test_true.append(test_label.numpy())\n",
    "              \n",
    "              test_true = np.concatenate(test_true)\n",
    "              test_pred = np.concatenate(test_pred)\n",
    "              val_auc =  roc_auc_score(test_true, test_pred) \n",
    "\n",
    "              writer.add_scalar('Optimizing AUCM Loss/AUCMLoss', np.mean(loss_total), epoch*len(trainloader) + idx)\n",
    "              writer.add_scalar('Optimizing AUCM Loss/VAL AUC', np.mean(val_auc), epoch*len(trainloader) + idx)\n",
    "\n",
    "              model.train()\n",
    "\n",
    "              if best_val_auc < val_auc:\n",
    "                 best_val_auc = val_auc\n",
    "                 torch.save(model.state_dict(), 'checkpoints/DenseNet121_OptimizeAUCM_id%d_best_model.pth' % class_id)\n",
    "              \n",
    "        print ('Epoch=%s, BatchID=[%s/%s] | AUCM_Loss=%f, Val_AUC=%.4f, lr=%.4f'%(epoch, idx, len(trainloader), loss.item(), val_auc,  optimizer.lr))\n",
    "\n",
    "print ('Best Val_AUC is %.4f'%best_val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Multi-Label Training\n",
    "- Optimizing Multi-Label AUC (5 tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyunmin\\Anaconda3\\envs\\pytorch10\\lib\\site-packages\\libauc\\datasets\\chexpert.py:35: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
      "C:\\Users\\Hyunmin\\Anaconda3\\envs\\pytorch10\\lib\\site-packages\\libauc\\datasets\\chexpert.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 191027 images in total, 23385 positive images, 167642 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1224\n",
      "\n",
      "Found 191027 images in total, 61493 positive images, 129534 negative images\n",
      "Edema(C1): imbalance ratio is 0.3219\n",
      "\n",
      "Found 191027 images in total, 12983 positive images, 178044 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0680\n",
      "\n",
      "Found 191027 images in total, 59583 positive images, 131444 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3119\n",
      "\n",
      "Found 191027 images in total, 76899 positive images, 114128 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4026\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 202 images in total, 66 positive images, 136 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.3267\n",
      "\n",
      "Found 202 images in total, 42 positive images, 160 negative images\n",
      "Edema(C1): imbalance ratio is 0.2079\n",
      "\n",
      "Found 202 images in total, 32 positive images, 170 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.1584\n",
      "\n",
      "Found 202 images in total, 75 positive images, 127 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3713\n",
      "\n",
      "Found 202 images in total, 64 positive images, 138 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.3168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "# Index: -1 denotes multi-label mode including 5 diseases\n",
    "traindSet = CheXpert(csv_path=root+'train.csv', image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='train', class_index=-1)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=-1)\n",
    "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    " \n",
    "lr = 0.1 # using smaller learning rate is better\n",
    "gamma = 500\n",
    "imratio = traindSet.imratio_list \n",
    "weight_decay = 1e-5\n",
    "margin = 1.0\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = DenseNet121(pretrained=True, last_activation=None, activations='relu', num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "Loss = AUCM_MultiLabel(imratio=imratio, num_classes=5)\n",
    "optimizer = PESG(model, \n",
    "                 a=Loss.a, \n",
    "                 b=Loss.b, \n",
    "                 alpha=Loss.alpha, \n",
    "                 lr=lr, \n",
    "                 gamma=gamma, \n",
    "                 margin=margin, \n",
    "                 weight_decay=weight_decay, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, BatchID [0/5970] | AUCM_Loss=0.454441, Val_AUC=0.5777, Best_Val_AUC=0.5777\n",
      "Epoch=0, BatchID [400/5970] | AUCM_Loss=0.542490, Val_AUC=0.8379, Best_Val_AUC=0.8379\n",
      "Epoch=0, BatchID [800/5970] | AUCM_Loss=0.394383, Val_AUC=0.8230, Best_Val_AUC=0.8379\n",
      "Epoch=0, BatchID [1200/5970] | AUCM_Loss=0.704749, Val_AUC=0.8331, Best_Val_AUC=0.8379\n",
      "Epoch=0, BatchID [1600/5970] | AUCM_Loss=0.521471, Val_AUC=0.8500, Best_Val_AUC=0.8500\n",
      "Epoch=0, BatchID [2000/5970] | AUCM_Loss=0.653860, Val_AUC=0.8318, Best_Val_AUC=0.8500\n",
      "Epoch=0, BatchID [2400/5970] | AUCM_Loss=0.641579, Val_AUC=0.8448, Best_Val_AUC=0.8500\n",
      "Epoch=0, BatchID [2800/5970] | AUCM_Loss=0.756936, Val_AUC=0.8616, Best_Val_AUC=0.8616\n",
      "Epoch=0, BatchID [3200/5970] | AUCM_Loss=0.446649, Val_AUC=0.8349, Best_Val_AUC=0.8616\n",
      "Epoch=0, BatchID [3600/5970] | AUCM_Loss=0.959618, Val_AUC=0.8551, Best_Val_AUC=0.8616\n",
      "Epoch=0, BatchID [4000/5970] | AUCM_Loss=0.560501, Val_AUC=0.8688, Best_Val_AUC=0.8688\n",
      "Epoch=0, BatchID [4400/5970] | AUCM_Loss=0.445698, Val_AUC=0.8267, Best_Val_AUC=0.8688\n",
      "Epoch=0, BatchID [4800/5970] | AUCM_Loss=0.421309, Val_AUC=0.8409, Best_Val_AUC=0.8688\n",
      "Epoch=0, BatchID [5200/5970] | AUCM_Loss=0.655942, Val_AUC=0.8409, Best_Val_AUC=0.8688\n",
      "Epoch=0, BatchID [5600/5970] | AUCM_Loss=0.554353, Val_AUC=0.8303, Best_Val_AUC=0.8688\n",
      "Reducing learning rate to 0.01000 @ T=5970!\n",
      "Updating regularizer @ T=5970!\n",
      "Epoch=1, BatchID [0/5970] | AUCM_Loss=0.594526, Val_AUC=0.8655, Best_Val_AUC=0.8688\n",
      "Epoch=1, BatchID [400/5970] | AUCM_Loss=0.469977, Val_AUC=0.8881, Best_Val_AUC=0.8881\n",
      "Epoch=1, BatchID [800/5970] | AUCM_Loss=0.455882, Val_AUC=0.8863, Best_Val_AUC=0.8881\n",
      "Epoch=1, BatchID [1200/5970] | AUCM_Loss=0.477626, Val_AUC=0.8778, Best_Val_AUC=0.8881\n",
      "Epoch=1, BatchID [1600/5970] | AUCM_Loss=0.306386, Val_AUC=0.8917, Best_Val_AUC=0.8917\n",
      "Epoch=1, BatchID [2000/5970] | AUCM_Loss=0.332157, Val_AUC=0.8939, Best_Val_AUC=0.8939\n",
      "Epoch=1, BatchID [2400/5970] | AUCM_Loss=0.337828, Val_AUC=0.8822, Best_Val_AUC=0.8939\n",
      "Epoch=1, BatchID [2800/5970] | AUCM_Loss=0.455413, Val_AUC=0.8859, Best_Val_AUC=0.8939\n",
      "Epoch=1, BatchID [3200/5970] | AUCM_Loss=0.773311, Val_AUC=0.8883, Best_Val_AUC=0.8939\n",
      "Epoch=1, BatchID [3600/5970] | AUCM_Loss=0.676710, Val_AUC=0.8895, Best_Val_AUC=0.8939\n",
      "Epoch=1, BatchID [4000/5970] | AUCM_Loss=0.292321, Val_AUC=0.8801, Best_Val_AUC=0.8939\n",
      "Epoch=1, BatchID [4400/5970] | AUCM_Loss=0.408692, Val_AUC=0.8832, Best_Val_AUC=0.8939\n",
      "Epoch=1, BatchID [4800/5970] | AUCM_Loss=0.580925, Val_AUC=0.8802, Best_Val_AUC=0.8939\n",
      "Epoch=1, BatchID [5200/5970] | AUCM_Loss=0.378864, Val_AUC=0.8852, Best_Val_AUC=0.8939\n",
      "Epoch=1, BatchID [5600/5970] | AUCM_Loss=0.310988, Val_AUC=0.8878, Best_Val_AUC=0.8939\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "best_val_auc = 0 \n",
    "loss_total = []\n",
    "\n",
    "for epoch in range(2):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)       \n",
    "    for idx, data in enumerate(trainloader):\n",
    "      train_data, train_labels = data           # train_labels.shape : torch.Size([32, 5])\n",
    "      train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n",
    "      y_pred = model(train_data)\n",
    "      y_pred = torch.sigmoid(y_pred)\n",
    "      loss = Loss(y_pred, train_labels)\n",
    "      loss_total += [loss.item()]\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "        \n",
    "      # validation  \n",
    "      if idx % 400 == 0:\n",
    "         model.eval()\n",
    "         with torch.no_grad():    \n",
    "              test_pred = []\n",
    "              test_true = [] \n",
    "              for jdx, data in enumerate(testloader):\n",
    "                  test_data, test_labels = data\n",
    "                  test_data = test_data.cuda()\n",
    "                  y_pred = model(test_data)\n",
    "                  y_pred = torch.sigmoid(y_pred)\n",
    "                  test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                  test_true.append(test_labels.numpy())\n",
    "            \n",
    "              test_true = np.concatenate(test_true)\n",
    "              test_pred = np.concatenate(test_pred)\n",
    "              val_auc_mean =  roc_auc_score(test_true, test_pred) \n",
    "\n",
    "              writer.add_scalar('Multi-Label Training/AUCM_MultiLabel', np.mean(loss_total), epoch*len(trainloader) + idx)\n",
    "              writer.add_scalar('Multi-Label Training/VAL AUC', np.mean(val_auc_mean), idx)\n",
    "              \n",
    "              model.train()\n",
    "\n",
    "              if best_val_auc < val_auc_mean:\n",
    "                 best_val_auc = val_auc_mean\n",
    "                 torch.save(model.state_dict(), 'checkpoints/DenseNet121_aucm_multi_label_pretrained_model.pth')\n",
    "\n",
    "              print ('Epoch=%s, BatchID [%s/%s] | AUCM_Loss=%f, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, len(trainloader), loss.item(), val_auc_mean, best_val_auc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1967738436216bbc6e595949f2989133cdf8326bfdf11bc95d02693bb68887ad"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('pytorch10': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
